{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-F-422 -  Statistical Foundations of Machine Learning \n",
    "\n",
    "### Student 1 - __[antoine.bedaton@ulb.be](mailto:antoine.bedaton@ulb.be) - Student ID 459482__\n",
    "### Student 2 - __[pierre.defraene@ulb.be](mailto:pierre.defraene@ulb.be) - Student ID 463941__\n",
    "### Student 3 - __[nathan.marotte@ulb.be](mailto:nathan.marotte@ulb.be) - Student ID 459274__\n",
    "\n",
    "### Video presentation: www.youtube.com/abcd1234\n",
    "\n",
    "## Project Title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data from Taarifa and the Tanzanian Ministry of Water, we are asked to predict which pump are functional, non functional, or functional but need some repairs. The data contains information about each pump (position, region name, population, type of payment, installator, etc ...) and comes in 3 files : \n",
    "\n",
    "- training_set_labels : Contains the list of all id followed by their status (functionning, non functionning or needing repairs)\n",
    "\n",
    "- training_set_values : Contains all the information about each pump with their id that correspond to training_set_labels\n",
    "\n",
    "- test_set_values : The same structure as training_set_values but for which the status is unknown and that we will have to predict.\n",
    "\n",
    "First, we will preprocess the data to remove redundent or useless information. For exemple the name of the pump isn't really relevant for guessing if it is working or not, while the name of the constructor is.\n",
    "\n",
    "Once we reduced the size of the input space, we will run our 3 models on the data, that is training_set_values with their status_group column added.\n",
    "\n",
    "Our group chose the 3 following models : \n",
    "\n",
    "- Decision Tree (rpart library)\n",
    "- Neural Network (nnet library)\n",
    "- Random Forest (randomForest library)\n",
    "\n",
    "Uncomment and execute the following cell to install all the require libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages('dummies')\n",
    "# install.packages('rpart')\n",
    "# install.packages('rpart.plot')\n",
    "# install.packages('nnet')\n",
    "# install.packages('randomForest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using R in version 3.6.1\n",
    "This can be checked by executing the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.version$version.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the data provided by the competition \"Pump it Up: Data Mining the Water Table\" available [here](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_labels <- read.csv(file = 'data/training_set_labels.csv', stringsAsFactors = T)\n",
    "test_set_values <- read.csv(file = 'data/test_set_values.csv', stringsAsFactors = T)\n",
    "training_set_values <- read.csv(file = 'data/training_set_values.csv', stringsAsFactors = T)\n",
    "\n",
    "#training_set_labels\n",
    "#summary(test_set_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "## The raw Data\n",
    "Here is the data as received, as we can see it contains a lot of column and rows, some of which might not be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Preprocessing\n",
    "\n",
    "Before starting the modeling, we must first process the data. We are given a huge number of columns and rows, some of which are not useful to determine the functioning of the pump. For instance, maybe the name of the pump is not important to guess if it is working or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing useless columns\n",
    "First we will check all the columns and check if, by chance, one column has always the same value. If there exist such a column, we can safely delete it since it doesn't bring any information to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (colname in names(training_set_values)) {\n",
    "    list_of_unique <- unique(training_set_values[colname])\n",
    "    if (nrow(list_of_unique) == 1){\n",
    "        print(paste(\"the column\", colname, \"has always the same value\"))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One column was found that is always the same value, we will then remove it from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"recorded_by\")] # remove recorded_by train_data\n",
    "\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"recorded_by\")] # remove recorded_by _train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the data in a less strict manner. What if for only a few of the entries, we have a different value ? This won't be detected with the above loop, but can be detected manually by checking the number of occurence of the most common value. If it appears, let's say more than 99 % of the time, we assume it is always that value and remove that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Computes the ratio of the value that appear the most compared to the rest of the data\n",
    "maxima <- c()\n",
    "for (colname in names(training_set_values)) {\n",
    "   maxima <- rbind(maxima, max(table(training_set_values[colname]))/59400)\n",
    "}\n",
    "\n",
    "# Shows it nicely\n",
    "df <- data.frame(names(training_set_values), maxima)\n",
    "df <- df[order(df$maxima, decreasing=TRUE),]\n",
    "head(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that num_private has almost 99% of the time the same value. Given the huge amount of columns and data, we do not feel that it is necessary to keep that information, it would only make the model more complicated for a slight change in the error rate. Therefore we delete that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"num_private\")] # remove num_private train_set\n",
    "\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"num_private\")] # remove num_private test_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the corelation between columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking through the data, we found multiple columns that were repeated. We suspected that `quantity` and `quantity_group` were highly corolated, so we ran the following command to check directly if there is a bijection for every variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(training_set_values$quantity, training_set_values$quantity_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that when `quantity` is `dry`, 100% of the time `quantity_group` is also dry. Those two columns have a corelation of 100%, it means one of the two is redundant and can safely be removed.\n",
    "\n",
    "We could then do that for all the combination of columns, but this isn't efficient and we can decide by ourselves by looking at what the columns represent, and test for corelation between them. This can be done via `chiqs.test` of the contingency table of the two columns. \n",
    "\n",
    "For exemple with `quantity` and `quantity_group` compared to `quantity` and `payment_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(table(training_set_values$quantity, training_set_values$quantity_group))\n",
    "chisq.test(table(training_set_values$quantity, training_set_values$payment_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a high X-squared value, this means the two columns are highly correlated. We also check with two uncorrelated columns to see that we indeed get a small X-squared value.\n",
    "\n",
    "We have to be careful with Chi-squared test since the degree of freedom also influences X-squared value. If we have a high degree of freedom, we might have more problems interpreting the X-square value because of that.\n",
    "\n",
    "We now have a way to check efficiently if two columns are correlated, so we will use that with the one we suspect are. We can also use the contingency table if we are not sure that they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(training_set_values)\n",
    "\n",
    "chisq.test(table(training_set_values$funder, training_set_values$payment_type))\n",
    "# table(training_set_values$funder, training_set_values$payment_type)  # We see that it's mostly random\n",
    "chisq.test(table(training_set_values$water_quality, training_set_values$quality_group))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "For this part, we will check our model and see if we cannot create new features for the data. For exemple we could merge `pay monthly` and `pay annualy` into `periodic_payment`.\n",
    "However we didn't find that very useful for the data presented.\n",
    "\n",
    "## Feature selection\n",
    "We want to look at the correlation between every input and the output. to do so we will make a `chiqs.test` for every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_correlation <- cbind(training_set_values,training_set_labels[2])\n",
    "\n",
    "chisq.test(table(test_correlation$amount_tsh, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$date_recorded, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$funder, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$gps_height, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$installer, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$longitude, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$latitude, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$wpt_name, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$basin, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$subvillage, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$region, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$region_code, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$district_code, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$lga, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$ward, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$population, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$public_meeting, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$scheme_management, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$scheme_name, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$permit, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$construction_year, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$extraction_type, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$management, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$payment, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$water_quality, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$quantity, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$source, test_correlation$status_group))\n",
    "chisq.test(table(test_correlation$waterpoint_type, test_correlation$status_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will look at pairs of columns that seem similar and compare their contingency table. \n",
    "\n",
    "The columns mentionned in the next cell are removed because of their contigency table with another column. We removed them if it indicated that they brought the same or less information to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options(repr.matrix.max.rows=10, repr.matrix.max.cols=100) # option pour la taille des prints\n",
    "\n",
    "\n",
    "\n",
    "# table(training_set_values$waterpoint_type_group, training_set_values$waterpoint_type)  # less information\n",
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"waterpoint_type_group\")]\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"waterpoint_type_group\")]\n",
    "\n",
    "# table(training_set_values$source_type, training_set_values$source_class)  # less information\n",
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"source_class\")]\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"source_class\")]\n",
    "\n",
    "# table(training_set_values$source, training_set_values$source_type)  # less information\n",
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"source_type\")]\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"source_type\")]\n",
    "\n",
    "# table(training_set_values$water_quality, training_set_values$quality_group)  # less information\n",
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"quality_group\")]\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"quality_group\")]\n",
    "\n",
    "# table(training_set_values$quantity, training_set_values$quantity_group)  # equivalent, we delete column\n",
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"quantity_group\")]\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"quantity_group\")]\n",
    "\n",
    "# table(training_set_values$extraction_type, training_set_values$extraction_type_group)  # we can delete column\n",
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"extraction_type_group\")]\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"extraction_type_group\")]\n",
    "\n",
    "# table(training_set_values$extraction_type, training_set_values$extraction_type_class)  # We can delete column\n",
    "# training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"extraction_type_class\")]\n",
    "\n",
    "# table(training_set_values$payment, training_set_values$payment_type)  # equivalent,  we delete column\n",
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"payment_type\")]\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"payment_type\")]\n",
    "\n",
    "# table(training_set_values$management, training_set_values$management_group)  # we delete column\n",
    "training_set_values <- training_set_values[,setdiff(colnames(training_set_values),\"management_group\")]\n",
    "test_set_values <- test_set_values[,setdiff(colnames(test_set_values),\"management_group\")]\n",
    "\n",
    "# table(training_set_values$region, training_set_values$region_code)  # very correlated but some cities/code are ambigius\n",
    "# table(training_set_values$basin, training_set_values$subvillage)  # not really correlated, keep\n",
    "\n",
    "\n",
    "# TODO REMOVE PRINT\n",
    "\n",
    "# head(training_set_values)\n",
    "names(training_set_values)\n",
    "length(names(training_set_values))\n",
    "#training_set_values[-c(40, 38, 37, 33, 35, 26, 27, 31, 29, 14, 12)]\n",
    "training_set_values\n",
    "# subvillage > region \n",
    "training_set_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value imputation\n",
    "In this part, we will have to replace missing value by something else. One approach could be to simply remove rows that are missing a value if they are not so common, otherwise we can also take the average of that column, or replace the missing value with the most common value. \n",
    "\n",
    "We chose to replace the empty value with a new category : `unknown`. This might be a  problem for the model since for exemple, it could indicate that all rows which `funder` is `unkown` are broken, but this could actually be truthful since, indeed, if the funder is unknown, maybe the pump has more chance of breaking\n",
    "\n",
    "This will be done for all the columns that contain text entries, since there isn't missing data for numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#head(training_set_values, 10)[3, 2]\n",
    "empty_check <- c(\"funder\", \"installer\", \"basin\", \"subvillage\", \"region\", \"lga\", \"ward\", \"scheme_management\", \"scheme_name\", \"permit\", \"extraction_type\", \"extraction_type_class\", \"payment\", \"water_quality\", \"quantity\", \"source\", \"waterpoint_type\", \"permit\", \"public_meeting\") \n",
    "for (row in 1:nrow(head(training_set_values, 10))){\n",
    "    #print(training_set_values[row])\n",
    "    for (col in 1:ncol(head(training_set_values, 10))){\n",
    "        col_name <- names(training_set_values[row])\n",
    "        if (col_name %in% empty_check){\n",
    "            if (is.na(training_set_values[row, col])){\n",
    "                print(paste(\"Changing\"))\n",
    "                training_set_values[row, col] = as.factor(\"unknown\")\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "head(training_set_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transform also categorical variable with 'one-hot-encoding'. To do so, we will use `dummies` package. To facilitate the work, we will merge the training set and the test set to have all different possibilities for each columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dummies)\n",
    "\n",
    "total_data <- rbind(training_set_values,test_set_values) # merge train and test to make dummies variable\n",
    "\n",
    "factor_variables <- which(sapply(total_data[1,],class)==\"factor\") # take only factor variable\n",
    "\n",
    "data_fact <- total_data[,factor_variables]\n",
    "\n",
    "only_num_var <- total_data[,-factor_variables]\n",
    "\n",
    "variables_to_keep <- c(\"waterpoint_type\",\"quantity\",\"extraction_type\") # variable to transform\n",
    "\n",
    "data_factor_onehot <- dummy.data.frame(data_fact[,variables_to_keep], sep=\"_\")\n",
    "\n",
    "\n",
    "data_factor_onehot[1:2,]\n",
    "\n",
    "dim(total_data)\n",
    "dim(training_set_values)\n",
    "\n",
    "total_with_dummies <- cbind(only_num_var,data_factor_onehot)\n",
    "\n",
    "# resplit data\n",
    "# data_train\n",
    "data_train <- total_with_dummies[1:59400,]\n",
    "data_train <- cbind(data_train, training_set_labels[2])\n",
    "\n",
    "data_train\n",
    "\n",
    "\n",
    "# data_test\n",
    "data_test <- total_with_dummies[59401:74250,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "\n",
    "As stated in the introduction, we used the three following models/libraries : \n",
    "\n",
    "- Decision Tree (rpart library)\n",
    "- Neural Network (nnet library)\n",
    "- Random Forest (randomForest library)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : Decision Tree\n",
    "We chose to use Decision tree since it is one of the simplest machine learning technique, and also that it can help us build intuition about what makes a pump functional or not. \n",
    "\n",
    "The decision tree produced might or might not be relevant to the real case problem, but it will be useful to predict the data of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "\n",
    "data_train\n",
    "\n",
    "# example model \n",
    "\n",
    "model<- rpart(status_group~., data= data_train, method = 'class') # creation of the model\n",
    "\n",
    "\n",
    "prp(model) # print tree\n",
    "\n",
    "predict_unseen <- predict(model,data_test, type = 'class') # prediction\n",
    "\n",
    "status_group <-predict_unseen\n",
    "\n",
    "data_predict <- test_set_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_predict <- cbind(data_predict[1],status_group)\n",
    "\n",
    "table(data_predict[\"status_group\"] == \"functional\")\n",
    "\n",
    "data_predict\n",
    "\n",
    "write.csv(data_predict,\"decisionTree.csv\",row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 : Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given how popular Neural Networks are, we will also use it for the data. However we do not expect enormous result with this model since Neural Network work better for other type of problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(nnet)\n",
    "\n",
    "data_train\n",
    "\n",
    "# example model \n",
    "\n",
    "\n",
    "nnet_model <- nnet(status_group~., data= data_train, size = 8, decay=5e-4, maxit=200) # what we need to change according of the model\n",
    "\n",
    "predict_unseen <- predict(nnet_model, data_test, type= 'class')\n",
    "\n",
    "status_group <-predict_unseen\n",
    "\n",
    "nnet_data_predict <- cbind(data_predict[1],status_group)\n",
    "\n",
    "nnet_data_predict\n",
    "\n",
    "table(nnet_data_predict[\"status_group\"] == \"functional\")\n",
    "\n",
    "write.csv(nnet_data_predict,\"NeuralNetwork.csv\",row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_unseen <- predict(nnet_model,only_num_var_train, type= 'class') # test nathan with know variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results <- table(ifelse(predict_unseen == training_set_labels$status_group, \"true\", \"false\"))\n",
    "#results[\"true\"]/(results[\"true\"]+results[\"false\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : Random Forest\n",
    "\n",
    "We chose this model because it is the continuity of decision tree and we think it is a good way to achieve a correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "library(\"randomForest\")\n",
    "\n",
    "rf_model<- randomForest(status_group~., data= data_train) # what we need to change according of the model\n",
    "\n",
    "\n",
    "rf_predict_unseen <- predict(rf_model,data_test, type = 'class')\n",
    "\n",
    "rf_predict_unseen\n",
    "\n",
    "status_group <-rf_predict_unseen\n",
    "\n",
    "rf_data_predict <- test_set_values\n",
    "\n",
    "\n",
    "rf_data_predict <- cbind(data_predict[1],status_group)\n",
    "\n",
    "\n",
    "rf_data_predict\n",
    "\n",
    "write.csv(rf_data_predict,\"randomForest.csv\",row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative models\n",
    "\n",
    "\n",
    "TODO : trouver un modÃ¨le qui n'existe pas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In conclusion, we found that decision tree / random forest works best between our 3 models, and we think it would be even better with more accurate data (for exemple pressure sensors, temperature sensors, etc ... ). \n",
    "\n",
    "Neural Network is also be a good candidate for this type of problem because it can create abstraction about data in a smarter way than Nearest Neighbor to understand that geographically close waterpumps might or might not suffer the same problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.6.1",
   "language": "R",
   "name": "ir361"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
